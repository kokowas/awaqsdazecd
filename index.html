<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ø³ÙˆØ±Ø© Ø§Ù„Ø²Ù„Ø²Ù„Ø© - ØªÙ„Ø§ÙˆØ© ÙˆØªØ¹Ø±Ù ØµÙˆØªÙŠ</title>
    <style>
        @font-face {
            font-family: 'HafsFont';
            src: url('conv_original-hafs.otf') format('opentype'); /* Ensure this font file is accessible */
            font-weight: normal;
            font-style: normal;
        }

        body {
            font-family: 'HafsFont', Arial, sans-serif;
            text-align: center;
            padding: 20px;
            direction: rtl;
            background-color: #f4f4f4;
            margin: 0;
            -webkit-tap-highlight-color: transparent; /* Prevent tap highlight on mobile */
        }

        h1 {
            font-size: 2em; /* Adjusted for general viewing */
            color: #333;
            margin-top: 15px;
            margin-bottom: 10px;
        }
        #speechStatus {
            font-size: 0.9em;
            color: #555;
            min-height: 2.5em; /* More space for messages */
            margin-bottom: 15px;
            padding: 5px;
            line-height: 1.4;
        }

        .bismillah-container {
            text-align: center;
            margin-bottom: 0.5em;
        }

        #sentence {
            font-size: 28px; /* Adjusted for general viewing */
            line-height: 2.4;
            max-width: 90%; /* Use percentage for better responsiveness */
            margin: 15px auto;
            text-align: right;
            padding: 12px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        #sentence > span:not(.ayah-number),
        .bismillah-container > span {
            display: inline-block;
            padding: 1px 3px;
            margin: 0 1px;
            border-radius: 3px;
            vertical-align: baseline;
            transition: background-color 0.15s ease-in-out, color 0.15s ease-in-out;
            visibility: hidden;
        }

        .highlight {
            visibility: visible !important;
            background-color: #00ff84;
            color: #000;
        }

        .spoken {
            visibility: visible !important;
            background-color: #c8f7dc;
            color: #333;
        }

        .controls button {
            padding: 12px 20px; /* Larger tap target */
            font-size: 20px; /* Adjusted */
            cursor: pointer;
            border: none;
            background: #007BFF;
            color: white;
            border-radius: 10px;
            margin: 10px 5px;
            min-width: 140px; /* Adjusted */
            line-height: 1.2;
            transition: background-color 0.3s ease;
        }
        .controls button:hover, .controls button:focus {
            background: #0056b3;
            outline: none;
        }
        .controls button:active {
            background: #004085;
        }
        .controls button#resetButton {
            background-color: #6c757d;
        }
        .controls button#resetButton:hover, .controls button#resetButton:focus {
            background-color: #5a6268;
        }
         .controls button#resetButton:active {
            background-color: #495057;
        }


        .ayah-number {
            color: #007BFF;
            font-size: 0.75em; /* Adjusted */
            margin: 0 3px;
            display: inline;
            visibility: visible !important;
        }

        /* Simpler media queries for general font scaling */
        @media (max-width: 600px) {
            h1 { font-size: 1.8em; }
            #sentence { font-size: 24px; line-height: 2.3; }
            .controls button { font-size: 18px; padding: 10px 15px; min-width: 120px; }
            .ayah-number { font-size: 0.7em; }
        }
        @media (max-width: 400px) {
            body { padding: 10px; }
            h1 { font-size: 1.6em; }
            #sentence { font-size: 20px; line-height: 2.2; }
            .controls button { font-size: 16px; padding: 8px 12px; min-width: 100px; }
            .ayah-number { font-size: 0.65em; }
        }
    </style>
</head>
<body>

    <h1>Ø³ÙˆØ±Ø© Ø§Ù„Ø²Ù„Ø²Ù„Ø©</h1>
    <div id="speechStatus">Ø§Ø¶ØºØ· "Ø§Ø¨Ø¯Ø£" ÙˆØªØ­Ø¯Ø«</div>

    <div class="controls">
        <button id="speechButton" onclick="toggleSpeechRecognition()">ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ø¯Ø«</button>
        <button id="resetButton" onclick="resetActivity()">ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø©</button>
    </div>

    <div id="sentence">
        <div class="bismillah-container">
            <span>Ø¨Ø³Ù…</span> <span>Ø§Ù„Ù„Ù‡</span> <span>Ø§Ù„Ø±Ø­Ù…Ù†</span> <span>Ø§Ù„Ø±Ø­ÙŠÙ…</span>
        </div>
        <span>Ø§Ø°Ø§</span> <span>Ø²Ù„Ø²Ù„Øª</span> <span>Ø§Ù„Ø§Ø±Ø¶</span> <span>Ø²Ù„Ø²Ø§Ù„Ù‡Ø§</span><span class="ayah-number">ÛÙ¡</span>
        <span>ÙˆØ§Ø®Ø±Ø¬Øª</span> <span>Ø§Ù„Ø§Ø±Ø¶</span> <span>Ø§Ø«Ù‚Ø§Ù„Ù‡Ø§</span><span class="ayah-number">ÛÙ¢</span>
        <span>ÙˆÙ‚Ø§Ù„</span> <span>Ø§Ù„Ø§Ù†Ø³Ø§Ù†</span> <span>Ù…Ø§</span> <span>Ù„Ù‡Ø§</span><span class="ayah-number">ÛÙ£</span>
        <span>ÙŠÙˆÙ…Ø¦Ø°</span> <span>ØªØ­Ø¯Ø«</span> <span>Ø§Ø®Ø¨Ø§Ø±Ù‡Ø§</span><span class="ayah-number">ÛÙ¤</span>
        <span>Ø¨Ø§Ù†</span> <span>Ø±Ø¨Ùƒ</span> <span>Ø§ÙˆØ­Ù‰</span> <span>Ù„Ù‡Ø§</span><span class="ayah-number">ÛÙ¥</span>
        <span>ÙŠÙˆÙ…Ø¦Ø°</span> <span>ÙŠØµØ¯Ø±</span> <span>Ø§Ù„Ù†Ø§Ø³</span> <span>Ø§Ø´ØªØ§ØªØ§</span> <span>Ù„ÙŠØ±ÙˆØ§</span> <span>Ø§Ø¹Ù…Ø§Ù„Ù‡Ù…</span><span class="ayah-number">ÛÙ¦</span>
        <span>ÙÙ…Ù†</span> <span>ÙŠØ¹Ù…Ù„</span> <span>Ù…Ø«Ù‚Ø§Ù„</span> <span>Ø°Ø±Ø©</span> <span>Ø®ÙŠØ±Ø§</span> <span>ÙŠØ±Ù‡</span><span class="ayah-number">ÛÙ§</span>
        <span>ÙˆÙ…Ù†</span> <span>ÙŠØ¹Ù…Ù„</span> <span>Ù…Ø«Ù‚Ø§Ù„</span> <span>Ø°Ø±Ø©</span> <span>Ø´Ø±Ø§</span> <span>ÙŠØ±Ù‡</span><span class="ayah-number">ÛÙ¨</span>
    </div>

<script>
    const speechButton = document.getElementById("speechButton");
    const speechStatus = document.getElementById("speechStatus");
    const sentenceContainer = document.getElementById("sentence");
    const wordSpans = Array.from(
        sentenceContainer.querySelectorAll('#sentence > span:not(.ayah-number), .bismillah-container > span')
    );

    let currentWordIndex = 0;
    let isRecognizing = false;
    let accumulatedFinalTranscript = "";
    let userManuallyStopped = false; // Flag to indicate if user explicitly stopped recognition
    let restartTimeoutId = null; // To manage the timeout for auto-restarting

    function normalizeArabic(text) {
        if (!text) return "";
        text = text.replace(/[Ø¥Ø£Ø¢Ù±]/g, "Ø§");
        text = text.replace(/Ù‰/g, "ÙŠ");
        text = text.replace(/Ø¤/g, "Ùˆ");
        text = text.replace(/Ø¦/g, "ÙŠ");
        text = text.replace(/Ø©/g, "Ù‡");
        return text.trim();
    }

    wordSpans.forEach(span => {
        const normalizedText = normalizeArabic(span.textContent);
        span.dataset.word = normalizedText;
    });

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition;

    if (SpeechRecognition) {
        recognition = new SpeechRecognition();
        recognition.continuous = true; // Keep listening
        recognition.interimResults = true; // Get results faster
        recognition.lang = 'ar-SA';

        recognition.onstart = () => {
            console.log("SpeechRecognition.onstart: Recognition started.");
            isRecognizing = true;
            userManuallyStopped = false; // Reset flag as recognition is actively starting
            accumulatedFinalTranscript = ""; // Clear previous partials
            speechButton.textContent = "ğŸ”´ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹...";
            speechStatus.textContent = "ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†...";
            speechButton.style.backgroundColor = '#dc3545';
        };

        recognition.onend = () => {
            console.log("SpeechRecognition.onend: Recognition ended. userManuallyStopped:", userManuallyStopped, "currentWordIndex:", currentWordIndex, "isRecognizing (before onend sets it false):", isRecognizing);
            const wasRecognizingBeforeEnd = isRecognizing; // Capture state
            isRecognizing = false; // Recognition has officially stopped

            // Always update button to "start" state initially; onstart will change it if auto-restarted successfully
            speechButton.textContent = "ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ø¯Ø«";
            speechButton.style.backgroundColor = '#007BFF';

            clearTimeout(restartTimeoutId); // Clear any previously scheduled restart

            if (!userManuallyStopped && currentWordIndex < wordSpans.length) {
                console.log("onend: Conditions met for auto-restart. Scheduling.");
                speechStatus.textContent = "Ù„Ø­Ø¸Ø©ØŒ ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹..."; // Feedback for auto-restart attempt
                
                restartTimeoutId = setTimeout(() => {
                    // Check conditions *again* inside timeout, as state might have changed by user action
                    if (!isRecognizing && !userManuallyStopped && currentWordIndex < wordSpans.length) {
                        console.log("onend (timeout): Re-checking conditions - still met. Starting recognition.");
                        try {
                            recognition.start(); // This will trigger onstart if successful
                        } catch (e) {
                            console.error("Auto-restart failed in timeout:", e);
                            speechStatus.textContent = "ÙØ´Ù„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: " + e.message;
                            // Ensure UI reflects definite stop state
                            speechButton.textContent = "ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ø¯Ø«";
                            speechButton.style.backgroundColor = '#007BFF';
                            userManuallyStopped = true; // Prevent further attempts if start fails critically
                        }
                    } else {
                        console.log("onend (timeout): Conditions for auto-restart no longer met (e.g., user manually stopped/reset or completed).");
                        // If not restarting, ensure status reflects the actual situation
                        if (userManuallyStopped) {
                           speechStatus.textContent = (currentWordIndex === 0) ? "Ø§Ø¶ØºØ· \"Ø§Ø¨Ø¯Ø£\" ÙˆØªØ­Ø¯Ø«" : "ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹. Ø§Ø¶ØºØ· Ù„Ù…ØªØ§Ø¨Ø¹Ø©.";
                        } else if (currentWordIndex >= wordSpans.length) {
                           speechStatus.textContent = "Ø£Ø­Ø³Ù†Øª! Ù…ÙƒØªÙ…Ù„. Ø§Ø¶ØºØ· Ù„Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø¬Ø¯ÙŠØ¯.";
                        } else {
                           speechStatus.textContent = "ØªÙˆÙ‚Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹."; // General fallback
                        }
                    }
                }, 250); // 250ms delay before attempting restart
            } else {
                // This block executes if user manually stopped, or Sura is complete, or a critical error set userManuallyStopped=true
                console.log("onend: Not auto-restarting. Updating final status based on state.");
                if (currentWordIndex >= wordSpans.length) {
                    speechStatus.textContent = "Ø£Ø­Ø³Ù†Øª! Ù…ÙƒØªÙ…Ù„. Ø§Ø¶ØºØ· Ù„Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø¬Ø¯ÙŠØ¯.";
                } else if (userManuallyStopped) { 
                    if (currentWordIndex > 0) {
                        speechStatus.textContent = "ØªÙˆÙ‚Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹. Ø§Ø¶ØºØ· Ù„Ù…ØªØ§Ø¨Ø¹Ø©.";
                    } else { // currentWordIndex === 0, implies reset or stopped at very beginning
                        speechStatus.textContent = "Ø§Ø¶ØºØ· \"Ø§Ø¨Ø¯Ø£\" ÙˆØªØ­Ø¯Ø«";
                    }
                } else {
                    // Fallback, should be less common now.
                    // Could happen if recognition ends without userManuallyStopped being true AND Sura not complete,
                    // but auto-restart conditions were somehow not met (e.g. wasRecognizingBeforeEnd was false unexpectedly)
                    speechStatus.textContent = "Ø§Ø¶ØºØ· \"Ø§Ø¨Ø¯Ø£\" ÙˆØªØ­Ø¯Ø«";
                }
                // userManuallyStopped remains as it was, reflecting the reason for not restarting.
                // It will be reset to false by the next successful 'onstart' or 'toggleSpeechRecognition' (when starting).
            }
        };

        recognition.onerror = (event) => {
            console.error("SpeechRecognition.onerror:", event.error, event.message);
            let errorMsg = "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØµÙˆØªÙŠ: " + event.error;
            if (event.error === 'no-speech') {
                errorMsg = "Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø£ÙŠ ÙƒÙ„Ø§Ù…. Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ­Ø¯Ø« Ø¨ÙˆØ¶ÙˆØ­.";
                // For 'no-speech', we don't set userManuallyStopped=true, allowing onend to attempt auto-restart.
            } else if (event.error === 'audio-capture') {
                errorMsg = "Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†.";
                userManuallyStopped = true; // Critical error, prevent auto-restart loop
            } else if (event.error === 'not-allowed') {
                errorMsg = "ØªÙ… Ø±ÙØ¶ Ø¥Ø°Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ÙˆØµÙˆÙ„ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØªØµÙØ­/Ø§Ù„Ù‡Ø§ØªÙ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆÙ‚Ø¹.";
                userManuallyStopped = true; // Critical error
            } else if (event.error === 'network') {
                errorMsg = "Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© ØªÙ…Ù†Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØµÙˆØªÙŠ.";
                userManuallyStopped = true; // Critical error
            } else if (event.error === 'aborted') {
                 errorMsg = "ØªÙˆÙ‚Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹."; // Often when stop() is called, or sometimes by browser.
                 // If aborted by user (via stop()), userManuallyStopped will be true.
                 // If aborted by browser after silence, userManuallyStopped will be false, onend will try to restart.
            } else if (event.error === 'service-not-allowed'){
                 errorMsg = "Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØµÙˆØªÙŠ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø¨Ø³Ø¨Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¬Ù‡Ø§Ø² Ø£Ùˆ Ø§Ù„Ù…ØªØµÙØ­).";
                 userManuallyStopped = true; // Critical error
            } else {
                userManuallyStopped = true; // For other unhandled errors, assume critical.
            }
            
            speechStatus.textContent = errorMsg;
            // isRecognizing will be set to false by onend, which always fires after an error according to spec.
            // UI updates for button will also be handled by onend.
            // If a critical error sets userManuallyStopped = true, onend will not auto-restart.
            console.log(`onerror: userManuallyStopped is now ${userManuallyStopped} due to error: ${event.error}`);
        };

        recognition.onresult = (event) => {
            let interimTranscript = '';
            let finalTranscriptSegment = ''; // To process only new final parts

            for (let i = event.resultIndex; i < event.results.length; ++i) {
                const transcriptPart = event.results[i][0].transcript;
                if (event.results[i].isFinal) {
                    finalTranscriptSegment += transcriptPart + " ";
                } else {
                    interimTranscript += transcriptPart;
                }
            }
            
            if (interimTranscript && isRecognizing) {
                speechStatus.textContent = "Ù„Ø­Ø¸Ø©... " + interimTranscript;
            }

            // Process the accumulated final transcript segment
            if (finalTranscriptSegment && currentWordIndex < wordSpans.length && isRecognizing) {
                accumulatedFinalTranscript += finalTranscriptSegment; // Add new final part to buffer
                console.log("Processing accumulated final transcript:", accumulatedFinalTranscript);
                
                const wordsToProcess = accumulatedFinalTranscript.trim().split(/\s+/); // Split by one or more spaces
                let processedWordsFromBuffer = 0;

                for (let spokenWord of wordsToProcess) {
                    if (!isRecognizing || currentWordIndex >= wordSpans.length) break;

                    const normalizedSpokenWord = normalizeArabic(spokenWord);
                    if (!normalizedSpokenWord) continue; 

                    const targetWordSpan = wordSpans[currentWordIndex];
                    const targetWordText = targetWordSpan.dataset.word;

                    if (targetWordText && normalizedSpokenWord === targetWordText) {
                        const previouslyHighlighted = document.querySelector('#sentence .highlight');
                        if (previouslyHighlighted && previouslyHighlighted !== targetWordSpan) {
                            previouslyHighlighted.classList.remove('highlight');
                            previouslyHighlighted.classList.add('spoken');
                        }
                        targetWordSpan.classList.remove('spoken');
                        targetWordSpan.classList.add('highlight');
                        currentWordIndex++;
                        processedWordsFromBuffer++;
                        
                        if (currentWordIndex < wordSpans.length && isRecognizing) {
                             speechStatus.textContent = "Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©...";
                        }
                    } else {
                        // Mismatch, stop processing this batch of words from buffer
                        // The mismatched word and subsequent words remain in accumulatedFinalTranscript for next attempt.
                        console.log(`Mismatch or partial: Spoken="${normalizedSpokenWord}" vs Target="${targetWordText}". Buffer: "${accumulatedFinalTranscript}"`);
                        break; 
                    }
                }
                
                // Clean up the processed words from the beginning of accumulatedFinalTranscript
                if (processedWordsFromBuffer > 0) {
                    accumulatedFinalTranscript = wordsToProcess.slice(processedWordsFromBuffer).join(" ") + " ";
                    if (accumulatedFinalTranscript.trim() === "") accumulatedFinalTranscript = ""; // Ensure it's empty if all processed
                }


                if (currentWordIndex >= wordSpans.length) {
                    speechStatus.textContent = "Ø£Ø­Ø³Ù†Øª! Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Øª Ø§Ù„Ø³ÙˆØ±Ø©.";
                    if (isRecognizing) {
                        console.log("All words matched, stopping recognition.");
                        // userManuallyStopped = false; // Not a manual stop, completion. onend will handle correctly.
                        recognition.stop(); 
                    }
                }
            }
        };

    } else {
        speechButton.disabled = true;
        speechButton.textContent = "Ø§Ù„Ù…ØªØµÙØ­ Ù„Ø§ ÙŠØ¯Ø¹Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª";
        speechStatus.textContent = "Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ØªØµÙØ­.";
        console.error("SpeechRecognition API not found.");
    }

    function toggleSpeechRecognition() {
        clearTimeout(restartTimeoutId); // Cancel any pending auto-restart immediately

        if (!SpeechRecognition) {
            console.warn("toggleSpeechRecognition: SpeechRecognition API not supported.");
            return;
        }
        console.log(`toggleSpeechRecognition called. Current state: isRecognizing = ${isRecognizing}`);

        if (isRecognizing) {
            console.log("toggleSpeechRecognition: User stopping. Setting userManuallyStopped=true.");
            userManuallyStopped = true; 
            recognition.stop(); // onend will be called, see userManuallyStopped=true, and not auto-restart.
        } else { // Not recognizing, user wants to start
            if (currentWordIndex >= wordSpans.length) {
                console.log("toggleSpeechRecognition: Sura complete, resetting activity before starting new session.");
                resetActivity(); // This resets state (e.g. currentWordIndex) and ensures clean UI for a new start.
                                 // resetActivity also sets userManuallyStopped = true, then calls stop if needed.
                                 // onend (if called by resetActivity's stop()) will see userManuallyStopped=true.
            }
            // Whether reset or not, we are now intending to start.
            console.log("toggleSpeechRecognition: User starting. Setting userManuallyStopped=false.");
            userManuallyStopped = false; // Explicitly intend to listen (and allow auto-restarts if needed)
            try {
                accumulatedFinalTranscript = ""; // Clear buffer for fresh start
                recognition.start(); // onstart will set isRecognizing = true and update UI.
            } catch (e) {
                console.error("toggleSpeechRecognition: Error calling recognition.start():", e);
                speechStatus.textContent = "Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ø±Ù: " + e.message;
                isRecognizing = false; 
                userManuallyStopped = true; // If start fails, treat as a stop.
                speechButton.textContent = "ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ø¯Ø«";
                speechButton.style.backgroundColor = '#007BFF';
            }
        }
    }

    function resetActivity() {
        console.log("resetActivity called.");
        clearTimeout(restartTimeoutId); // Cancel any pending auto-restart

        currentWordIndex = 0;
        accumulatedFinalTranscript = "";
        wordSpans.forEach(span => {
            span.style.visibility = 'hidden'; // Explicitly hide
            span.classList.remove('highlight', 'spoken');
        });
        
        userManuallyStopped = true; // This stop is intentional from reset, should not auto-restart.
        
        if (isRecognizing) {
            console.log("resetActivity: Recognition was active, calling recognition.stop().");
            recognition.stop(); // onend will fire. It will see userManuallyStopped = true and not auto-restart.
                                // onend will then handle UI updates (button text, status).
        } else {
            // Not currently recognizing (e.g. initial page load, or already stopped).
            // onend won't fire, so set UI directly to clean "ready to start" state.
            console.log("resetActivity: Recognition not active. Resetting UI directly.");
            speechButton.textContent = "ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ø¯Ø«";
            speechButton.style.backgroundColor = '#007BFF';
            speechStatus.textContent = "Ø§Ø¶ØºØ· \"Ø§Ø¨Ø¯Ø£\" ÙˆØªØ­Ø¯Ø«";
            isRecognizing = false; // Ensure consistency
            // userManuallyStopped remains true from above; next explicit start will set it to false.
        }
    }

    // Initial setup call on page load
    resetActivity();
    console.log("Page loaded. Initial reset done. Ready for user to start.");

</script>
</body>
</html>